{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb370621",
   "metadata": {},
   "source": [
    "## 0. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceef4de",
   "metadata": {},
   "source": [
    "**Названия столбцов таблицы**\n",
    "- PTID - Participant ID - уникальный идентификатор пациента\n",
    "- IMAGEUID - Image Unique ID - уникальный идентификатор изображения MRI\n",
    "- EXAMDATE - Examination Date - дата проведения обследования\n",
    "- SITE - Site ID - идентификатор исследовательского центра\n",
    "- AGE - Age at baseline - возраст на момент включения в исследование\n",
    "- PTGENDER - Participant Gender - пол пациента\n",
    "- PTEDUCAT - Participant Education - годы образования\n",
    "- PTETHCAT - Participant Ethnic Category - этническая принадлежность\n",
    "- PTRACCAT - Participant Race Category - расовая принадлежность\n",
    "- PTMARRY - Participant Marital Status - семейное положение\n",
    "- APOE4 - APOE ε4 allele carrier status - статус носительства аллеля APOE4 (фактор риска болезни Альцгеймера)\n",
    "- Month и M - Months from baseline - месяцы от момента включения в исследование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d0348",
   "metadata": {},
   "source": [
    "*Клинические и нейропсихологические тесты:*\n",
    "- CDRSB - общий балл по шкале оценки деменции\n",
    "- ADAS11 - шкала оценки болезни Альцгеймера (11 пунктов)\n",
    "- ADAS13 - шкала оценки болезни Альцгеймера (13 пунктов)\n",
    "- ADASQ4 - тест на запоминание слов из ADAS\n",
    "- MMSE - краткая шкала оценки психического статуса\n",
    "- RAVLT_immediate - немедленное воспроизведение\n",
    "- RAVLT_learning - обучение/запоминание\n",
    "- RAVLT_forgetting - забывание\n",
    "- RAVLT_perc_forgetting - процент забывания\n",
    "- LDELTOTAL - отсроченное воспроизведение логической памяти\n",
    "- LDELTOTAL_BL - базовый уровень отсроченного воспроизведения\n",
    "- TRABSCOR -  тест следования связям (часть B)\n",
    "- FAQ - опросник функциональной активности\n",
    "- mPACCdigit - модифицированный доклинический когнитивный композит (цифры)\n",
    "- mPACCtrailsB - модифицированный доклинический когнитивный композит (следование связям B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfe68f",
   "metadata": {},
   "source": [
    "*Метрики по областям мозга:*\n",
    "- Столбцы начинающиеся с ST - это объемы конкретных регионов мозга после сегментации:\n",
    "- ST...SV - Subcortical Volume (подкорковый объем)\n",
    "- ST...CV - Cortical Volume (корковый объем)\n",
    "- ST...SA - Surface Area (площадь поверхности)\n",
    "- ST...TA - Total Area (общая площадь)\n",
    "- ST...TS - Thickness (толщина коры)\n",
    "\n",
    "Где ... - номер региона по FreeSurfer. Например:\n",
    "\n",
    "ST101SV - Left Thalamus volume (левый таламус)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40cf3eb",
   "metadata": {},
   "source": [
    "Основные подкорковые структуры (+ SV - Subcortical Volume):\n",
    "\n",
    "- ST101SV - Left Thalamus (левый таламус)\n",
    "- ST102SV - Left Caudate (левое хвостатое ядро)\n",
    "- ST103SV - Left Putamen (левая скорлупа)\n",
    "- ST104SV - Left Pallidum (левый бледный шар)\n",
    "- ST105SV - Left Hippocampus (левый гиппокамп)\n",
    "- ST107SV - Left Accumbens area (левая прилежащая область)\n",
    "- ST108SV - Left Ventral DC (левый вентральный диэнцефалон)\n",
    "- ST109SV - Right Thalamus (правый таламус)\n",
    "- ST110SV - Right Caudate (правое хвостатое ядро)\n",
    "- ST111SV - Right Putamen (правая скорлупа)\n",
    "- ST112SV - Right Pallidum (правый бледный шар)\n",
    "- ST113SV - Right Hippocampus (правый гиппокамп)\n",
    "- ST114SV - Right Amygdala (правое миндалевидное тело)\n",
    "- ST115SV - Right Accumbens area (правая прилежащая область)\n",
    "- ST116SV - Right Ventral DC (правый вентральный диэнцефалон)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcb43e",
   "metadata": {},
   "source": [
    "Корковые регионы (+ CV - Cortical Volume, SA - Surface Area, TA - Thickness):\n",
    "\n",
    "- Лобная доля (Frontal Lobe):\n",
    "  - ST23 - Left Superior Frontal (левая верхняя лобная извилина)\n",
    "  - ST24 - Left Rostral Middle Frontal (левая ростральная средняя лобная)\n",
    "  - ST25 - Left Caudal Middle Frontal (левая каудальная средняя лобная)\n",
    "  - ST26 - Left Precentral (левая прецентральная извилина)\n",
    "  - ST31 - Left Pars Opercularis (левая покрышечная часть)\n",
    "  - ST32 - Left Pars Triangularis (левая треугольная часть)\n",
    "  - ST34 - Left Lateral Orbitofrontal (левая латеральная орбитофронтальная)\n",
    "  - ST35 - Left Medial Orbitofrontal (левая медиальная орбитофронтальная)\n",
    "  - ST38 - Left Frontal Pole (левый лобный полюс)\n",
    "- Височная доля (Temporal Lobe):\n",
    "  - ST13 - Left Entorhinal (левая энторинальная кора)\n",
    "  - ST14 - Left Fusiform (левая веретенообразная извилина)\n",
    "  - ST15 - Left Inferior Temporal (левая нижняя височная извилина)\n",
    "  - ST39 - Left Middle Temporal (левая средняя височная извилина)\n",
    "  - ST40 - Left Superior Temporal (левая верхняя височная извилина)\n",
    "  - ST43 - Left Banks STS (левый банк верхней височной борозды)\n",
    "  - ST44 - Left Transverse Temporal (левая поперечная височная извилина)\n",
    "  - ST45 - Left Temporal Pole (левый височный полюс)\n",
    "- Теменная доля (Parietal Lobe):\n",
    "  - ST46 - Left Inferior Parietal (левая нижняя теменная доля)\n",
    "  - ST47 - Left Superior Parietal (левая верхняя теменная доля)\n",
    "  - ST48 - Left Postcentral (левая постцентральная извилина)\n",
    "  - ST49 - Left Supramarginal (левая надкраевая извилина)\n",
    "  - ST54 - Left Precuneus (левая предклиньевая извилина)\n",
    "- Затылочная доля (Occipital Lobe):\n",
    "  - ST55 - Left Lateral Occipital (левая латеральная затылочная)\n",
    "  - ST56 - Left Lingual (левая язычная извилина)\n",
    "  - ST57 - Left Cuneus (левая клиновидная извилина)\n",
    "  - ST58 - Left Pericalcarine (левая околошпорная кора)\n",
    "- Другие важные регионы:\n",
    "  - ST59 - Left Insula (левый островок)\n",
    "  - ST60 - Left Cingulate (левая поясная извилина)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63b1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa046dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/sechenovka/res_diag.csv\")\n",
    "df['EXAMDATE'] = pd.to_datetime(df['EXAMDATE'])\n",
    "df_sorted = df.sort_values(['PTID', 'EXAMDATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d966e87",
   "metadata": {},
   "source": [
    "## 1. Прогноз когнитивных тестов. Предсказать MMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96f598",
   "metadata": {},
   "source": [
    "Задача заключается в прогнозировании будущего значения когнитивного теста MMSE в следущее посещение на основании текущих показателей пациента. Для каждого пациента предварительно вычисляется `MMSE_future` на основе упорядоченной последовательности отсортированных значений на основе `EXAMDATE` для одного и того же идентификатора `PTID`.\n",
    "\n",
    "Это может быть полезно для для раннего выявления ухудшения когнитивного состояния и оценки скорости прогрессирования когнитивных нарушений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83cc20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_140949\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       17.16 GB / 31.64 GB (54.2%)\n",
      "Disk Space Avail:   378.06 GB / 838.35 GB (45.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_140949\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           XGBoost_BAG_L1      -2.446941  -2.469363  root_mean_squared_error        0.726795       0.031044    5.222242                 0.726795                0.031044           5.222242            1       True          7\n",
      "1          CatBoost_BAG_L2      -2.514403  -2.742817  root_mean_squared_error        2.286084       0.372084   86.469796                 0.127204                0.075223           3.390071            2       True         12\n",
      "2     ExtraTreesMSE_BAG_L1      -2.562907  -2.200701  root_mean_squared_error        0.140849       0.084778    0.485816                 0.140849                0.084778           0.485816            1       True          5\n",
      "3   RandomForestMSE_BAG_L1      -2.597731  -2.297330  root_mean_squared_error        0.086767       0.059448    3.186620                 0.086767                0.059448           3.186620            1       True          3\n",
      "4          CatBoost_BAG_L1      -2.646231  -2.367526  root_mean_squared_error        0.404401       0.041170   63.967892                 0.404401                0.041170          63.967892            1       True          4\n",
      "5      WeightedEnsemble_L2      -2.649779  -2.106953  root_mean_squared_error        0.952260       0.165199   10.707969                 0.011343                0.000000           0.004998            2       True          8\n",
      "6        LightGBMXT_BAG_L1      -2.672741  -2.284024  root_mean_squared_error        0.371622       0.018824    1.696171                 0.371622                0.018824           1.696171            1       True          1\n",
      "7      WeightedEnsemble_L3      -2.674554  -2.104810  root_mean_squared_error        2.443216       0.374633  109.671051                 0.012004                0.000000           0.006000            3       True         13\n",
      "8          LightGBM_BAG_L1      -2.687761  -2.244101  root_mean_squared_error        0.133219       0.016836    3.177766                 0.133219                0.016836           3.177766            1       True          2\n",
      "9        LightGBMXT_BAG_L2      -2.729150  -2.272307  root_mean_squared_error        2.328901       0.335276   91.670430                 0.170021                0.038416           8.590705            2       True          9\n",
      "10  NeuralNetFastAI_BAG_L1      -2.803531  -2.238154  root_mean_squared_error        0.666850       0.063585    7.039388                 0.666850                0.063585           7.039388            1       True          6\n",
      "11         LightGBM_BAG_L2      -2.875274  -2.225512  root_mean_squared_error        2.431213       0.374633  109.665051                 0.272332                0.077772          26.585326            2       True         10\n",
      "12  RandomForestMSE_BAG_L2      -2.986159  -2.267123  root_mean_squared_error        2.244657       0.356350   85.470834                 0.085776                0.059489           2.391109            2       True         11\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t157s\t = DyStack   runtime |\t443s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 443s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_140949\"\n",
      "Train Data Rows:    474\n",
      "Train Data Columns: 324\n",
      "Label Column:       MMSE_future\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17239.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.17 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 324 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 324 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t324 features in original data used to generate 324 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 442.90s of the 442.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.40%)\n",
      "\t-2.2591\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 438.01s of the 438.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.40%)\n",
      "\t-2.2998\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 432.15s of the 432.14s of remaining time.\n",
      "\t-2.3169\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 429.08s of the 429.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.84%)\n",
      "\t-2.3636\t = Validation score   (-root_mean_squared_error)\n",
      "\t73.39s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 353.64s of the 353.64s of remaining time.\n",
      "\t-2.2773\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 353.01s of the 353.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-2.3482\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.63s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 343.25s of the 343.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.87%)\n",
      "\t-2.3517\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.87s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 330.07s of the 330.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
      "\t-2.5262\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.11s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 315.66s of the 315.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.61%)\n",
      "\t-2.4944\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 294.36s of the 294.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.93%)\n",
      "\t-2.3645\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.27s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 238.15s of the 238.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t-2.3381\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.03s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 224.36s of the 224.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.65%)\n",
      "\t-2.2851\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 215.12s of the 215.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-2.3672\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 205.54s of the 205.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.35%)\n",
      "\t-2.4828\t = Validation score   (-root_mean_squared_error)\n",
      "\t164.71s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 38.54s of the 38.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.22%)\n",
      "\t-2.3815\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 32.21s of the 32.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t-2.3739\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.64s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 17.43s of the 17.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.29%)\n",
      "\t-2.5378\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.62s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 0.60s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.391, 'LightGBMXT_BAG_L1': 0.217, 'RandomForestMSE_BAG_L1': 0.174, 'ExtraTreesMSE_BAG_L1': 0.13, 'NeuralNetFastAI_BAG_L1': 0.043, 'XGBoost_BAG_L1': 0.043}\n",
      "\t-2.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 442.49s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 287.7 rows/s (60 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_140949\")\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(['PTID', 'EXAMDATE'])\n",
    "\n",
    "df_sorted['MMSE_future'] = df_sorted.groupby('PTID')['MMSE'].shift(-1)\n",
    "df_sorted = df_sorted.dropna(subset=['MMSE_future'])\n",
    "\n",
    "\n",
    "unique_ptids = df_sorted['PTID'].unique()\n",
    "train_ptids, test_ptids = train_test_split(unique_ptids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_sorted[df_sorted['PTID'].isin(train_ptids)]\n",
    "df_test = df_sorted[df_sorted['PTID'].isin(test_ptids)]\n",
    "\n",
    "cortical_cols = [col for col in df_sorted.columns if col.startswith('ST')]\n",
    "features = cortical_cols + ['MMSE']\n",
    "target = 'MMSE_future'\n",
    "\n",
    "train_data = df_train[features + [target]].dropna()\n",
    "test_data = df_test[features + [target]].dropna()\n",
    "\n",
    "\n",
    "predictor1 = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ee3830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance Metrics:\n",
      "root_mean_squared_error: -2.0906\n",
      "mean_squared_error: -4.3705\n",
      "mean_absolute_error: -1.4600\n",
      "r2: 0.5511\n",
      "pearsonr: 0.7535\n",
      "median_absolute_error: -1.0172\n"
     ]
    }
   ],
   "source": [
    "performance = predictor1.evaluate(test_data)\n",
    "print(\"Test Performance Metrics:\")\n",
    "for metric, value in performance.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8825707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 324 features using 109 rows with 5 shuffle sets...\n",
      "\t732.56s\t= Expected runtime (146.51s per shuffle set)\n",
      "\t61.17s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "         importance    stddev   p_value  n  p99_high   p99_low\n",
      "MMSE       0.734195  0.094890  0.000033  5  0.929576  0.538815\n",
      "ST7SV      0.024057  0.004500  0.000140  5  0.033323  0.014791\n",
      "ST129SA    0.022580  0.012918  0.008708  5  0.049178 -0.004018\n",
      "ST129CV    0.020710  0.010174  0.005202  5  0.041659 -0.000238\n",
      "ST102TA    0.015785  0.004692  0.000836  5  0.025446  0.006124\n",
      "ST14TA     0.015588  0.011055  0.017209  5  0.038351 -0.007175\n",
      "ST69SV     0.013852  0.006530  0.004508  5  0.027297  0.000406\n",
      "ST31TA     0.013703  0.003895  0.000706  5  0.021724  0.005683\n",
      "ST43TS     0.012771  0.005653  0.003612  5  0.024410  0.001131\n",
      "ST95TS     0.012447  0.004891  0.002354  5  0.022517  0.002378\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor1.feature_importance(test_data)\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990e568",
   "metadata": {},
   "source": [
    "Так, для предсказания будущего `MMSE` важно значение текущего `MMSE` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b3d14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.146439</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.320543</td>\n",
       "      <td>36.101317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-2.259097</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>2.094033</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>2.094033</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-2.277340</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_r131_BAG_L1</td>\n",
       "      <td>-2.285125</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>7.234866</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>7.234866</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-2.299812</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>3.711538</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>3.711538</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val              eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -2.146439  root_mean_squared_error       0.320543   \n",
       "1     LightGBMXT_BAG_L1  -2.259097  root_mean_squared_error       0.021909   \n",
       "2  ExtraTreesMSE_BAG_L1  -2.277340  root_mean_squared_error       0.067600   \n",
       "3  LightGBM_r131_BAG_L1  -2.285125  root_mean_squared_error       0.019973   \n",
       "4       LightGBM_BAG_L1  -2.299812  root_mean_squared_error       0.018097   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  36.101317                0.000000           0.014002            2   \n",
       "1   2.094033                0.021909           2.094033            1   \n",
       "2   0.509253                0.067600           0.509253            1   \n",
       "3   7.234866                0.019973           7.234866            1   \n",
       "4   3.711538                0.018097           3.711538            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         18  \n",
       "1       True          1  \n",
       "2       True          5  \n",
       "3       True         12  \n",
       "4       True          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor1.leaderboard(silent=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c17615",
   "metadata": {},
   "source": [
    "## 2. Прогноз диагностической конверсии. CN → MCI, MCI → AD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589815d",
   "metadata": {},
   "source": [
    "Задача заключается в прогнозировании будущего диагноза пациента — вероятности перехода от нормального когнитивного состояния (`CN`) к лёгкому когнитивному нарушению (`MCI`) и далее к болезни Альцгеймера (`AD`). На основе данных о последовательных посещениях (`PTID`, `EXAMDATE`) и показателиях коры головного мозга происходит классификация будущего состояния на момент следующего визита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb4b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_142052\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       17.57 GB / 31.64 GB (55.6%)\n",
      "Disk Space Avail:   377.97 GB / 838.35 GB (45.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_142052\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     RandomForestGini_BAG_L1       0.789474   0.666667    accuracy        0.075926       0.086704   0.663754                 0.075926                0.086704           0.663754            1       True          3\n",
      "1              XGBoost_BAG_L1       0.789474   0.729167    accuracy        0.365485       0.020000   1.015028                 0.365485                0.020000           1.015028            1       True          9\n",
      "2     RandomForestEntr_BAG_L1       0.736842   0.701389    accuracy        0.061406       0.046289   0.465605                 0.061406                0.046289           0.465605            1       True          4\n",
      "3             LightGBM_BAG_L1       0.736842   0.743056    accuracy        0.106034       0.012014   0.479871                 0.106034                0.012014           0.479871            1       True          2\n",
      "4           LightGBMXT_BAG_L1       0.736842   0.708333    accuracy        0.245198       0.010987   0.430154                 0.245198                0.010987           0.430154            1       True          1\n",
      "5             CatBoost_BAG_L1       0.736842   0.722222    accuracy        0.455853       0.035507  26.760136                 0.455853                0.035507          26.760136            1       True          5\n",
      "6           LightGBMXT_BAG_L2       0.736842   0.784722    accuracy        1.868769       0.305013  37.959110                 0.110626                0.019628           0.430110            2       True         15\n",
      "7       ExtraTreesGini_BAG_L1       0.684211   0.715278    accuracy        0.058543       0.048845   0.465813                 0.058543                0.048845           0.465813            1       True          6\n",
      "8        LightGBMLarge_BAG_L1       0.684211   0.701389    accuracy        0.138356       0.015013   1.540797                 0.138356                0.015013           1.540797            1       True         11\n",
      "9        CatBoost_r177_BAG_L1       0.684211   0.770833    accuracy        0.151333       0.034460  20.843233                 0.151333                0.034460          20.843233            1       True         12\n",
      "10  NeuralNetTorch_r79_BAG_L1       0.684211   0.777778    accuracy        0.225369       0.078728   7.725745                 0.225369                0.078728           7.725745            1       True         13\n",
      "11        WeightedEnsemble_L2       0.684211   0.784722    accuracy        0.299985       0.128576   8.232130                 0.016073                0.001002           0.040571            2       True         14\n",
      "12     NeuralNetFastAI_BAG_L1       0.684211   0.736111    accuracy        0.789973       0.045049   6.533704                 0.789973                0.045049           6.533704            1       True          8\n",
      "13      ExtraTreesEntr_BAG_L2       0.684211   0.722222    accuracy        1.820354       0.333886  37.977600                 0.062211                0.048501           0.448601            2       True         21\n",
      "14      ExtraTreesGini_BAG_L2       0.684211   0.722222    accuracy        1.822744       0.333824  37.994223                 0.064601                0.048438           0.465224            2       True         20\n",
      "15    RandomForestEntr_BAG_L2       0.684211   0.770833    accuracy        1.823071       0.332863  38.030221                 0.064928                0.047478           0.501221            2       True         18\n",
      "16    RandomForestGini_BAG_L2       0.684211   0.701389    accuracy        1.840106       0.377994  38.070250                 0.081963                0.092608           0.541250            2       True         17\n",
      "17            LightGBM_BAG_L2       0.684211   0.798611    accuracy        1.859895       0.306218  38.057639                 0.101752                0.020832           0.528639            2       True         16\n",
      "18            CatBoost_BAG_L2       0.684211   0.833333    accuracy        1.893001       0.391052  57.834858                 0.134858                0.105667          20.305859            2       True         19\n",
      "19        WeightedEnsemble_L3       0.684211   0.833333    accuracy        1.903928       0.392016  57.873041                 0.010926                0.000964           0.038183            3       True         24\n",
      "20      ExtraTreesEntr_BAG_L1       0.631579   0.680556    accuracy        0.060318       0.048666   0.460988                 0.060318                0.048666           0.460988            1       True          7\n",
      "21      NeuralNetTorch_BAG_L1       0.631579   0.736111    accuracy        0.256887       0.080125   6.911384                 0.256887                0.080125           6.911384            1       True         10\n",
      "22             XGBoost_BAG_L2       0.631579   0.812500    accuracy        2.019878       0.309384  38.549316                 0.261735                0.023998           1.020316            2       True         23\n",
      "23     NeuralNetFastAI_BAG_L2       0.631579   0.784722    accuracy        2.076483       0.335500  43.973092                 0.318340                0.050115           6.444092            2       True         22\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t160s\t = DyStack   runtime |\t440s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 440s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_142052\"\n",
      "Train Data Rows:    163\n",
      "Train Data Columns: 323\n",
      "Label Column:       DX_future\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15814.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.40 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 323 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 323 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t323 features in original data used to generate 323 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.40 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 439.76s of the 439.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.40%)\n",
      "\t0.773\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 436.27s of the 436.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
      "\t0.7669\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 432.61s of the 432.60s of remaining time.\n",
      "\t0.6871\t = Validation score   (accuracy)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 431.89s of the 431.89s of remaining time.\n",
      "\t0.6748\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 431.25s of the 431.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.25%)\n",
      "\t0.7669\t = Validation score   (accuracy)\n",
      "\t23.29s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 405.82s of the 405.81s of remaining time.\n",
      "\t0.6258\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 405.24s of the 405.24s of remaining time.\n",
      "\t0.6871\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 404.61s of the 404.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.816\t = Validation score   (accuracy)\n",
      "\t8.65s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 393.65s of the 393.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.95%)\n",
      "\t0.7423\t = Validation score   (accuracy)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 389.09s of the 389.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.7301\t = Validation score   (accuracy)\n",
      "\t8.72s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 378.01s of the 378.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.89%)\n",
      "\t0.7178\t = Validation score   (accuracy)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 372.47s of the 372.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.55%)\n",
      "\t0.7669\t = Validation score   (accuracy)\n",
      "\t22.76s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 347.53s of the 347.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.7669\t = Validation score   (accuracy)\n",
      "\t10.25s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 335.09s of the 335.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.69%)\n",
      "\t0.7239\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 331.57s of the 331.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.7975\t = Validation score   (accuracy)\n",
      "\t9.79s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 319.35s of the 319.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.05%)\n",
      "\t0.7975\t = Validation score   (accuracy)\n",
      "\t112.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 204.52s of the 204.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.21%)\n",
      "\t0.6748\t = Validation score   (accuracy)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 201.69s of the 201.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.7485\t = Validation score   (accuracy)\n",
      "\t7.56s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 192.12s of the 192.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.08%)\n",
      "\t0.7301\t = Validation score   (accuracy)\n",
      "\t4.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 185.37s of the 185.37s of remaining time.\n",
      "\t0.6626\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 184.51s of the 184.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.84%)\n",
      "\t0.8037\t = Validation score   (accuracy)\n",
      "\t9.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 173.27s of the 173.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.7914\t = Validation score   (accuracy)\n",
      "\t7.46s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 163.79s of the 163.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.94%)\n",
      "\t0.7853\t = Validation score   (accuracy)\n",
      "\t96.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 64.90s of the 64.89s of remaining time.\n",
      "\t0.6748\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 63.96s of the 63.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.59%)\n",
      "\t0.7607\t = Validation score   (accuracy)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 60.12s of the 60.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.8098\t = Validation score   (accuracy)\n",
      "\t7.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 49.96s of the 49.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.95%)\n",
      "\t0.7485\t = Validation score   (accuracy)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 45.52s of the 45.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.7853\t = Validation score   (accuracy)\n",
      "\t8.16s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 35.29s of the 35.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.31%)\n",
      "\t0.6564\t = Validation score   (accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 32.15s of the 32.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.7914\t = Validation score   (accuracy)\n",
      "\t7.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 22.15s of the 22.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.20%)\n",
      "\t0.7546\t = Validation score   (accuracy)\n",
      "\t14.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 5.74s of the 5.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.773\t = Validation score   (accuracy)\n",
      "\t7.25s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -3.82s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.816\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 443.81s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 381.6 rows/s (21 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_142052\")\n"
     ]
    }
   ],
   "source": [
    "df_sorted['DX_future'] = df_sorted.groupby('PTID')['DX'].shift(-1)\n",
    "df_sorted = df_sorted.dropna(subset=['DX_future'])\n",
    "\n",
    "valid_classes = ['CN', 'MCI', 'AD']\n",
    "df_sorted = df_sorted[\n",
    "    df_sorted['DX'].isin(valid_classes) & df_sorted['DX_future'].isin(valid_classes)\n",
    "]\n",
    "\n",
    "\n",
    "unique_ptids = df_sorted['PTID'].unique()\n",
    "train_ptids, test_ptids = train_test_split(unique_ptids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_sorted[df_sorted['PTID'].isin(train_ptids)]\n",
    "df_test  = df_sorted[df_sorted['PTID'].isin(test_ptids)]\n",
    "\n",
    "\n",
    "cortical_cols = [col for col in df_sorted.columns if col.startswith('ST')]\n",
    "\n",
    "features = cortical_cols\n",
    "target = 'DX_future'\n",
    "\n",
    "train_data = df_train[features + [target]].dropna()\n",
    "test_data  = df_test[features + [target]].dropna()\n",
    "\n",
    "predictor2 = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='accuracy'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fee7b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance metrics:\n",
      "accuracy: 0.6087\n",
      "balanced_accuracy: 0.6192\n",
      "mcc: 0.2385\n"
     ]
    }
   ],
   "source": [
    "performance = predictor2.evaluate(test_data)\n",
    "print(\"Test performance metrics:\")\n",
    "for metric, value in performance.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0076f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.54      0.70      0.61        20\n",
      "         MCI       0.70      0.54      0.61        26\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.62      0.62      0.61        46\n",
      "weighted avg       0.63      0.61      0.61        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = test_data[target]\n",
    "y_pred = predictor2.predict(test_data)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d64f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>8.701074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047411</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>8.653662</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>8.653662</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.051659</td>\n",
       "      <td>7.645485</td>\n",
       "      <td>0.051659</td>\n",
       "      <td>7.645485</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_r137_BAG_L1</td>\n",
       "      <td>0.803681</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.032582</td>\n",
       "      <td>9.004255</td>\n",
       "      <td>0.032582</td>\n",
       "      <td>9.004255</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_r9_BAG_L1</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>112.345280</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>112.345280</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score_val eval_metric  pred_time_val  \\\n",
       "0          WeightedEnsemble_L2   0.815951    accuracy       0.055038   \n",
       "1       NeuralNetFastAI_BAG_L1   0.815951    accuracy       0.055038   \n",
       "2  NeuralNetFastAI_r145_BAG_L1   0.809816    accuracy       0.051659   \n",
       "3         CatBoost_r137_BAG_L1   0.803681    accuracy       0.032582   \n",
       "4           CatBoost_r9_BAG_L1   0.797546    accuracy       0.035357   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    8.701074                0.000000           0.047411            2   \n",
       "1    8.653662                0.055038           8.653662            1   \n",
       "2    7.645485                0.051659           7.645485            1   \n",
       "3    9.004255                0.032582           9.004255            1   \n",
       "4  112.345280                0.035357         112.345280            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         33  \n",
       "1       True          8  \n",
       "2       True         26  \n",
       "3       True         21  \n",
       "4       True         16  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.leaderboard(silent=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba568c7",
   "metadata": {},
   "source": [
    "## 3. Прогноз изменения объёмов мозга. Предсказать скорость уменьшения Hippocampus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b631205",
   "metadata": {},
   "source": [
    "В данной задаче прогнозируется скорость атрофии гиппокампа. На осснове данных извлеченных из последовательных визитов, структурных характеристик коры головного мозга (`STxx`) и клиническо-когнитивных параметров пациента, таких как `MMSE`, `CDRSB`, `ADAS13`, `AGE`, `APOE4`, `PTEDUCAT` предсказывается `atrophy_rate`.\n",
    "\n",
    "Такой подход может быть полезен для раннего выявления нейродегенеративных процессов, оценки эффективности терапии и моделирования динамики атрофии мозга в исследованиях болезни Альцгеймера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36e8207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_143224\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       16.07 GB / 31.64 GB (50.8%)\n",
      "Disk Space Avail:   377.86 GB / 838.35 GB (45.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_143224\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          LightGBM_BAG_L1    -162.341156 -163.523276  root_mean_squared_error        0.159203       0.015518   1.488650                 0.159203                0.015518           1.488650            1       True          2\n",
      "1          CatBoost_BAG_L1    -162.489584 -163.195125  root_mean_squared_error        0.451385       0.038575  38.167164                 0.451385                0.038575          38.167164            1       True          4\n",
      "2          CatBoost_BAG_L2    -163.406690 -163.099676  root_mean_squared_error        2.436015       0.446829  78.478260                 0.123310                0.095304          10.083968            2       True         14\n",
      "3          LightGBM_BAG_L2    -163.445830 -157.393944  root_mean_squared_error        2.522331       0.399853  85.518685                 0.209626                0.048328          17.124393            2       True         12\n",
      "4        LightGBMXT_BAG_L1    -163.604569 -162.446265  root_mean_squared_error        0.309139       0.020412   0.888156                 0.309139                0.020412           0.888156            1       True          1\n",
      "5      WeightedEnsemble_L2    -164.158022 -160.627808  root_mean_squared_error        0.907613       0.134462  21.058098                 0.012507                0.001000           0.005000            2       True         10\n",
      "6    NeuralNetTorch_BAG_L1    -164.202046 -160.761051  root_mean_squared_error        0.245339       0.077099   7.386315                 0.245339                0.077099           7.386315            1       True          8\n",
      "7     LightGBMLarge_BAG_L1    -164.280027 -163.919928  root_mean_squared_error        0.113194       0.023538   9.064293                 0.113194                0.023538           9.064293            1       True          9\n",
      "8   NeuralNetFastAI_BAG_L1    -165.612417 -163.471463  root_mean_squared_error        0.776155       0.063563   6.383295                 0.776155                0.063563           6.383295            1       True          6\n",
      "9           XGBoost_BAG_L1    -166.036932 -163.127722  root_mean_squared_error        0.340628       0.035951  12.778628                 0.340628                0.035951          12.778628            1       True          7\n",
      "10       LightGBMXT_BAG_L2    -166.605070 -154.492592  root_mean_squared_error        2.593656       0.411542  78.697706                 0.280952                0.060017          10.303414            2       True         11\n",
      "11     WeightedEnsemble_L3    -166.605070 -154.492592  root_mean_squared_error        2.603671       0.411542  78.702710                 0.010015                0.000000           0.005005            3       True         15\n",
      "12  RandomForestMSE_BAG_L2    -167.316904 -170.722453  root_mean_squared_error        2.410738       0.411930  70.674969                 0.098033                0.060404           2.280677            2       True         13\n",
      "13  RandomForestMSE_BAG_L1    -167.332379 -173.797692  root_mean_squared_error        0.114083       0.056371   2.260307                 0.114083                0.056371           2.260307            1       True          3\n",
      "14    ExtraTreesMSE_BAG_L1    -173.825473 -171.874643  root_mean_squared_error        0.075976       0.059555   0.530428                 0.075976                0.059555           0.530428            1       True          5\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t155s\t = DyStack   runtime |\t445s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 445s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_143224\"\n",
      "Train Data Rows:    427\n",
      "Train Data Columns: 329\n",
      "Label Column:       atrophy_rate\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16065.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\t0.3s = Fit runtime\n",
      "\t329 features in original data used to generate 329 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 444.52s of the 444.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.41%)\n",
      "\t-163.5661\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 440.99s of the 440.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.43%)\n",
      "\t-162.3079\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 436.36s of the 436.35s of remaining time.\n",
      "\t-172.672\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 433.21s of the 433.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.92%)\n",
      "\t-161.9238\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.91s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 391.27s of the 391.26s of remaining time.\n",
      "\t-172.2535\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 390.55s of the 390.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-162.2187\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 381.93s of the 381.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.89%)\n",
      "\t-162.6143\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.63s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 365.01s of the 365.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t-161.6728\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.15s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 354.55s of the 354.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.77%)\n",
      "\t-164.3185\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 338.22s of the 338.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.22%)\n",
      "\t-161.5035\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.57s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 293.20s of the 293.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t-168.1067\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.68s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 282.44s of the 282.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.74%)\n",
      "\t-162.1246\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 277.32s of the 277.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-162.8421\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 267.56s of the 267.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.34%)\n",
      "\t-163.3773\t = Validation score   (-root_mean_squared_error)\n",
      "\t179.2s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 85.86s of the 85.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
      "\t-162.9803\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 82.78s of the 82.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t-164.7212\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.69s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 71.76s of the 71.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.69%)\n",
      "\t-162.5499\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.25s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 28.07s of the 28.06s of remaining time.\n",
      "\t-172.6338\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 27.36s of the 27.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.63%)\n",
      "\t-161.1124\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.14s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 11.23s of the 11.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-175.2666\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.08s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -0.17s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L1': 0.48, 'NeuralNetTorch_BAG_L1': 0.28, 'NeuralNetFastAI_BAG_L1': 0.24}\n",
      "\t-160.459\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 445.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 318.7 rows/s (54 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_143224\")\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(['PTID', 'EXAMDATE'])\n",
    "hippo_col = 'Hippocampus'\n",
    "df_sorted = df_sorted.dropna(subset=[hippo_col])\n",
    "\n",
    "df_sorted['HIPPO_next'] = df_sorted.groupby('PTID')[hippo_col].shift(-1)\n",
    "df_sorted['EXAMDATE_next'] = df_sorted.groupby('PTID')['EXAMDATE'].shift(-1)\n",
    "df_sorted['time_years'] = (df_sorted['EXAMDATE_next'] - df_sorted['EXAMDATE']).dt.days / 365.25\n",
    "df_sorted = df_sorted[df_sorted['time_years'] > 0.1]\n",
    "df_sorted['atrophy_rate'] = (df_sorted['HIPPO_next'] - df_sorted[hippo_col]) / df_sorted['time_years']\n",
    "df_sorted = df_sorted.dropna(subset=['atrophy_rate'])\n",
    "\n",
    "unique_ptids = df_sorted['PTID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ptids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_sorted[df_sorted['PTID'].isin(train_ids)]\n",
    "df_test  = df_sorted[df_sorted['PTID'].isin(test_ids)]\n",
    "\n",
    "cortical_cols = [col for col in df.columns if col.startswith('ST')]\n",
    "extra_cols = ['MMSE', 'AGE', 'APOE4', 'PTEDUCAT', 'CDRSB', 'ADAS13']\n",
    "extra_cols_available = [col for col in extra_cols if col in df.columns]\n",
    "features = cortical_cols + extra_cols_available\n",
    "target = 'atrophy_rate'\n",
    "\n",
    "train_data = df_train[features + [target]].dropna()\n",
    "test_data  = df_test[features + [target]].dropna()\n",
    "\n",
    "predictor3 = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4b7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance metrics:\n",
      "root_mean_squared_error: -160.8497\n",
      "mean_squared_error: -25872.6338\n",
      "mean_absolute_error: -115.2029\n",
      "r2: 0.0022\n",
      "pearsonr: 0.0592\n",
      "median_absolute_error: -91.4070\n"
     ]
    }
   ],
   "source": [
    "performance = predictor3.evaluate(test_data)\n",
    "print(\"Test performance metrics:\")\n",
    "for metric, value in performance.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84888d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 329 features using 116 rows with 5 shuffle sets...\n",
      "\t319.72s\t= Expected runtime (63.94s per shuffle set)\n",
      "\t43.41s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "         importance    stddev   p_value  n  p99_high   p99_low\n",
      "CDRSB      0.250856  0.165031  0.013652  5  0.590658 -0.088946\n",
      "MMSE       0.177269  0.166348  0.037876  5  0.519782 -0.165243\n",
      "ST84CV     0.167676  0.091058  0.007321  5  0.355165 -0.019813\n",
      "ST45SA     0.134995  0.199252  0.102179  5  0.545258 -0.275268\n",
      "APOE4      0.094668  0.045336  0.004762  5  0.188016  0.001319\n",
      "ST47TS     0.093830  0.084414  0.033906  5  0.267640 -0.079980\n",
      "ADAS13     0.088854  0.055052  0.011288  5  0.202207 -0.024500\n",
      "ST25TS     0.069418  0.029026  0.002947  5  0.129184  0.009653\n",
      "ST54CV     0.069138  0.048141  0.016274  5  0.168262 -0.029986\n",
      "ST119CV    0.066469  0.046497  0.016506  5  0.162207 -0.029270\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor3.feature_importance(test_data)\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9a2476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-160.458997</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.170315</td>\n",
       "      <td>29.097454</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_r137_BAG_L1</td>\n",
       "      <td>-161.112440</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>14.137603</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>14.137603</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_r177_BAG_L1</td>\n",
       "      <td>-161.503476</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>42.569879</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>42.569879</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-161.672818</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.081316</td>\n",
       "      <td>8.146847</td>\n",
       "      <td>0.081316</td>\n",
       "      <td>8.146847</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-161.923843</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.033017</td>\n",
       "      <td>39.910030</td>\n",
       "      <td>0.033017</td>\n",
       "      <td>39.910030</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model   score_val              eval_metric  pred_time_val  \\\n",
       "0    WeightedEnsemble_L2 -160.458997  root_mean_squared_error       0.170315   \n",
       "1   CatBoost_r137_BAG_L1 -161.112440  root_mean_squared_error       0.032807   \n",
       "2   CatBoost_r177_BAG_L1 -161.503476  root_mean_squared_error       0.039188   \n",
       "3  NeuralNetTorch_BAG_L1 -161.672818  root_mean_squared_error       0.081316   \n",
       "4        CatBoost_BAG_L1 -161.923843  root_mean_squared_error       0.033017   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  29.097454                0.000999           0.006000            2   \n",
       "1  14.137603                0.032807          14.137603            1   \n",
       "2  42.569879                0.039188          42.569879            1   \n",
       "3   8.146847                0.081316           8.146847            1   \n",
       "4  39.910030                0.033017          39.910030            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         21  \n",
       "1       True         19  \n",
       "2       True         10  \n",
       "3       True          8  \n",
       "4       True          4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor3.leaderboard(silent=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db16262",
   "metadata": {},
   "source": [
    "Учитывая метрики и качество полученной модели, в качестве предположения было решено попробовать уменьшить количество признаков до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "646fa292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 329 features using 116 rows with 5 shuffle sets...\n",
      "\t333.03s\t= Expected runtime (66.61s per shuffle set)\n",
      "\t44.92s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_144359\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       15.52 GB / 31.64 GB (49.0%)\n",
      "Disk Space Avail:   377.76 GB / 838.35 GB (45.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_144359\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_r177_BAG_L1    -160.901999 -157.509041  root_mean_squared_error        0.108394       0.012001   1.961014                 0.108394                0.012001           1.961014            1       True         10\n",
      "1               CatBoost_BAG_L1    -161.192890 -157.387339  root_mean_squared_error        0.398191       0.009001   2.208034                 0.398191                0.009001           2.208034            1       True          4\n",
      "2          LightGBMLarge_BAG_L1    -162.230279 -158.998621  root_mean_squared_error        0.159811       0.009015   1.692519                 0.159811                0.009015           1.692519            1       True          9\n",
      "3           LightGBM_r96_BAG_L1    -163.155646 -157.943809  root_mean_squared_error        0.132341       0.006005   0.488106                 0.132341                0.006005           0.488106            1       True         15\n",
      "4        NeuralNetFastAI_BAG_L2    -163.185034 -152.513982  root_mean_squared_error        1.739785       0.356171  33.329220                 0.347862                0.048892           6.092794            2       True         23\n",
      "5            CatBoost_r9_BAG_L1    -163.904303 -156.962593  root_mean_squared_error        0.125519       0.010992   5.912490                 0.125519                0.010992           5.912490            1       True         14\n",
      "6        NeuralNetFastAI_BAG_L1    -164.185398 -157.540437  root_mean_squared_error        0.796395       0.061264   6.610080                 0.796395                0.061264           6.610080            1       True          6\n",
      "7          LightGBMLarge_BAG_L2    -164.198147 -153.115400  root_mean_squared_error        1.491565       0.315278  28.037875                 0.099643                0.008000           0.801450            2       True         26\n",
      "8               LightGBM_BAG_L1    -164.230695 -156.466188  root_mean_squared_error        0.102034       0.003003   0.416251                 0.102034                0.003003           0.416251            1       True          2\n",
      "9                XGBoost_BAG_L1    -164.462283 -157.040484  root_mean_squared_error        0.402972       0.020665   0.697647                 0.402972                0.020665           0.697647            1       True          7\n",
      "10            LightGBMXT_BAG_L1    -164.656789 -157.171756  root_mean_squared_error        0.345217       0.006491   0.409869                 0.345217                0.006491           0.409869            1       True          1\n",
      "11              CatBoost_BAG_L2    -165.064846 -150.671249  root_mean_squared_error        1.514659       0.324288  30.843054                 0.122736                0.017009           3.606629            2       True         21\n",
      "12  NeuralNetFastAI_r191_BAG_L1    -165.480190 -152.871001  root_mean_squared_error        0.330188       0.050997   6.630090                 0.330188                0.050997           6.630090            1       True         13\n",
      "13         LightGBM_r131_BAG_L1    -166.085184 -156.236990  root_mean_squared_error        0.118430       0.007030   0.375510                 0.118430                0.007030           0.375510            1       True         12\n",
      "14        NeuralNetTorch_BAG_L2    -166.536474 -151.874847  root_mean_squared_error        1.593547       0.368002  36.005205                 0.201624                0.060724           8.768780            2       True         25\n",
      "15          WeightedEnsemble_L2    -166.578774 -149.070839  root_mean_squared_error        1.079670       0.118094  20.399134                 0.012156                0.000000           0.005558            2       True         17\n",
      "16        NeuralNetTorch_BAG_L1    -166.738934 -155.067485  root_mean_squared_error        0.186384       0.039449   9.123556                 0.186384                0.039449           9.123556            1       True          8\n",
      "17         CatBoost_r177_BAG_L2    -166.932778 -150.830485  root_mean_squared_error        1.486299       0.326324  30.061857                 0.094377                0.019045           2.825432            2       True         27\n",
      "18               XGBoost_BAG_L2    -167.240931 -154.354661  root_mean_squared_error        1.709145       0.333284  28.465261                 0.317223                0.026005           1.228836            2       True         24\n",
      "19         ExtraTreesMSE_BAG_L2    -167.831830 -155.422151  root_mean_squared_error        1.483925       0.360304  27.619971                 0.092002                0.053025           0.383546            2       True         22\n",
      "20          WeightedEnsemble_L3    -167.962906 -147.644857  root_mean_squared_error        1.887875       0.369178  33.889838                 0.011000                0.000000           0.005509            3       True         28\n",
      "21            LightGBMXT_BAG_L2    -169.839636 -149.017615  root_mean_squared_error        1.529012       0.320285  27.791534                 0.137090                0.013007           0.555109            2       True         18\n",
      "22       RandomForestMSE_BAG_L1    -170.106805 -163.796966  root_mean_squared_error        0.112570       0.116781   0.445835                 0.112570                0.116781           0.445835            1       True          3\n",
      "23    NeuralNetTorch_r22_BAG_L1    -170.431926 -151.514382  root_mean_squared_error        0.215925       0.039402  12.690328                 0.215925                0.039402          12.690328            1       True         16\n",
      "24              LightGBM_BAG_L2    -172.020989 -149.549056  root_mean_squared_error        1.495644       0.318286  27.690839                 0.103721                0.011008           0.454414            2       True         19\n",
      "25       RandomForestMSE_BAG_L2    -172.561608 -154.296910  root_mean_squared_error        1.497706       0.385620  27.679231                 0.105784                0.078341           0.442806            2       True         20\n",
      "26         ExtraTreesMSE_BAG_L1    -173.893335 -161.604158  root_mean_squared_error        0.086319       0.061412   0.484524                 0.086319                0.061412           0.484524            1       True          5\n",
      "27    NeuralNetTorch_r79_BAG_L1    -177.436163 -153.132838  root_mean_squared_error        0.274143       0.050771   9.604960                 0.274143                0.050771           9.604960            1       True         11\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t157s\t = DyStack   runtime |\t443s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 443s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_144359\"\n",
      "Train Data Rows:    427\n",
      "Train Data Columns: 10\n",
      "Label Column:       atrophy_rate\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15379.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['CDRSB', 'MMSE', 'ST84CV', 'ST45SA', 'APOE4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['CDRSB', 'MMSE', 'ST84CV', 'ST45SA', 'APOE4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 442.91s of the 442.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-159.7917\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 440.12s of the 440.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-160.4891\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 437.03s of the 437.02s of remaining time.\n",
      "\t-163.5596\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 436.49s of the 436.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.66%)\n",
      "\t-156.9941\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 432.22s of the 432.21s of remaining time.\n",
      "\t-163.4029\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 431.56s of the 431.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.4033\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.29s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 422.13s of the 422.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
      "\t-159.9538\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 418.39s of the 418.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-157.6957\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 407.00s of the 407.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.14%)\n",
      "\t-162.5374\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 403.75s of the 403.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.67%)\n",
      "\t-156.252\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 399.25s of the 399.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.2079\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 387.05s of the 387.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
      "\t-161.1969\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 383.75s of the 383.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-155.0807\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 373.99s of the 373.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.96%)\n",
      "\t-158.1177\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 365.26s of the 365.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-159.8968\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 362.45s of the 362.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-157.3348\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.71s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 347.52s of the 347.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
      "\t-160.6046\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 343.47s of the 343.46s of remaining time.\n",
      "\t-163.6374\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 342.79s of the 342.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.50%)\n",
      "\t-155.9605\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 339.10s of the 339.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-155.2435\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.32s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 328.61s of the 328.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.94%)\n",
      "\t-157.6331\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 317.95s of the 317.94s of remaining time.\n",
      "\t-164.4091\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 317.29s of the 317.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.13%)\n",
      "\t-158.7613\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 314.49s of the 314.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-158.8765\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.2s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 305.13s of the 305.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
      "\t-159.6929\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 301.70s of the 301.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.5956\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 287.29s of the 287.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
      "\t-160.6334\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 284.55s of the 284.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.8104\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 273.27s of the 273.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.74%)\n",
      "\t-157.2076\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 269.14s of the 269.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-161.8124\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 259.42s of the 259.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
      "\t-161.1545\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 255.71s of the 255.71s of remaining time.\n",
      "\t-159.6637\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 255.17s of the 255.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.77%)\n",
      "\t-157.131\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 251.15s of the 251.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.0417\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 242.17s of the 242.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.7232\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.94s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 229.76s of the 229.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.25%)\n",
      "\t-160.8222\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 226.78s of the 226.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.7366\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 214.11s of the 214.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.83%)\n",
      "\t-157.6951\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 208.45s of the 208.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.0265\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.24s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 196.95s of the 196.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.14%)\n",
      "\t-159.0669\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 192.98s of the 192.97s of remaining time.\n",
      "\t-163.1725\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 192.41s of the 192.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.52%)\n",
      "\t-157.6094\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 187.37s of the 187.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-158.0908\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 178.27s of the 178.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-153.7131\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.83s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 164.94s of the 164.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.13%)\n",
      "\t-160.5336\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 161.08s of the 161.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-160.0393\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 157.79s of the 157.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.9468\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 142.75s of the 142.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.61%)\n",
      "\t-158.6318\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 135.96s of the 135.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.5656\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.53s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 123.24s of the 123.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.2221\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.53s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 113.62s of the 113.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.87%)\n",
      "\t-156.0136\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 109.15s of the 109.15s of remaining time.\n",
      "\t-163.9223\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 108.33s of the 108.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
      "\t-160.5133\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 104.81s of the 104.80s of remaining time.\n",
      "\t-161.8433\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 104.00s of the 103.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.2542\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 89.39s of the 89.38s of remaining time.\n",
      "\t-160.7546\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 88.90s of the 88.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-159.872\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 85.72s of the 85.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-155.2514\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 71.61s of the 71.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.71%)\n",
      "\t-158.1918\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 63.86s of the 63.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.4132\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.1s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 52.52s of the 52.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-155.8529\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 37.86s of the 37.86s of remaining time.\n",
      "\t-160.3805\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 37.35s of the 37.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-159.5929\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.63s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 25.55s of the 25.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t-154.4319\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.25s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 13.05s of the 13.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.11%)\n",
      "\t-159.4732\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 9.62s of the 9.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t-159.659\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 6.17s of the 6.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.58%)\n",
      "\t-156.2468\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1.46s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r41_BAG_L1': 0.391, 'NeuralNetFastAI_r111_BAG_L1': 0.391, 'CatBoost_r137_BAG_L1': 0.217}\n",
      "\t-149.9246\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 441.51s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 417.7 rows/s (54 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_144359\")\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "feature_importance = predictor3.feature_importance(test_data)\n",
    "top_features = feature_importance.head(N).index.tolist()\n",
    "\n",
    "train_data_reduced = train_data[top_features + [target]].dropna()\n",
    "test_data_reduced  = test_data[top_features + [target]].dropna()\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor_reduced = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data_reduced,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2effb3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on reduced feature set:\n",
      "root_mean_squared_error: -157.8487\n",
      "mean_squared_error: -24916.2004\n",
      "mean_absolute_error: -113.7511\n",
      "r2: 0.0391\n",
      "pearsonr: 0.2043\n",
      "median_absolute_error: -93.0927\n"
     ]
    }
   ],
   "source": [
    "performance_reduced = predictor_reduced.evaluate(test_data_reduced)\n",
    "\n",
    "print(\"Performance on reduced feature set:\")\n",
    "for metric, value in performance_reduced.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83fd92",
   "metadata": {},
   "source": [
    "## 4.  Прогноз функционального статуса. Изменение FAQ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41182700",
   "metadata": {},
   "source": [
    "В данной задаче целью является предсказание функционального статуса. В качестве примера берется изменение FAQ (Functional Activities Questionnaire), отражающий степень нарушения повседневной активности. Прогноз строится на основе кортикальных морфометрических признаков (STxx) и клиническо-когнитивных параметров — `MMSE`, `AGE`, `APOE4`, `PTEDUCAT`, `CDRSB`, `ADAS13`, с учётом последовательных посещений (`PTID`, `EXAMDATE`).\n",
    "\n",
    "Целевой переменной берется `FAQ_future`, то есть предсказывается значение для опросника в следующий визит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0f1c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_145358\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       16.25 GB / 31.64 GB (51.4%)\n",
      "Disk Space Avail:   377.49 GB / 838.35 GB (45.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_145358\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestMSE_BAG_L1      -2.894362  -3.331005  root_mean_squared_error        0.098114       0.052003    0.804094                 0.098114                0.052003           0.804094            1       True          3\n",
      "1     ExtraTreesMSE_BAG_L2      -2.935970  -3.331171  root_mean_squared_error        2.258358       0.429466   68.933306                 0.052150                0.056557           0.399471            2       True         15\n",
      "2   RandomForestMSE_BAG_L2      -3.126994  -3.499871  root_mean_squared_error        2.277581       0.449990   69.212843                 0.071373                0.077081           0.679009            2       True         13\n",
      "3     ExtraTreesMSE_BAG_L1      -3.309997  -3.238958  root_mean_squared_error        0.052239       0.050471    0.410445                 0.052239                0.050471           0.410445            1       True          5\n",
      "4        LightGBMXT_BAG_L2      -3.321707  -3.283630  root_mean_squared_error        2.314674       0.396938   69.086067                 0.108467                0.024029           0.552233            2       True         11\n",
      "5      WeightedEnsemble_L2      -3.361061  -3.179686  root_mean_squared_error        0.316541       0.117771    1.749645                 0.013004                0.000000           0.004997            2       True         10\n",
      "6      WeightedEnsemble_L3      -3.363258  -3.169792  root_mean_squared_error        2.589981       0.451243   76.580235                 0.009912                0.000000           0.004947            3       True         17\n",
      "7     LightGBMLarge_BAG_L1      -3.412771  -3.299451  root_mean_squared_error        0.160553       0.021028    9.470826                 0.160553                0.021028           9.470826            1       True          9\n",
      "8          LightGBM_BAG_L2      -3.465438  -3.247170  root_mean_squared_error        2.309225       0.392946   69.150615                 0.103017                0.020038           0.616781            2       True         12\n",
      "9          CatBoost_BAG_L2      -3.549779  -3.542758  root_mean_squared_error        2.337743       0.465652  101.095747                 0.131536                0.092743          32.561913            2       True         14\n",
      "10         LightGBM_BAG_L1      -3.679225  -3.281726  root_mean_squared_error        0.153184       0.015297    0.530109                 0.153184                0.015297           0.530109            1       True          2\n",
      "11       LightGBMXT_BAG_L1      -3.714640  -3.501849  root_mean_squared_error        0.375937       0.014830    0.474168                 0.375937                0.014830           0.474168            1       True          1\n",
      "12          XGBoost_BAG_L1      -3.788786  -3.707025  root_mean_squared_error        0.339448       0.021479    2.921005                 0.339448                0.021479           2.921005            1       True          7\n",
      "13         CatBoost_BAG_L1      -3.792759  -3.612578  root_mean_squared_error        0.552929       0.044798   46.974226                 0.552929                0.044798          46.974226            1       True          4\n",
      "14  NeuralNetFastAI_BAG_L1      -4.218984  -4.184841  root_mean_squared_error        0.765463       0.060730    7.615698                 0.765463                0.060730           7.615698            1       True          6\n",
      "15  NeuralNetFastAI_BAG_L2      -4.224853  -3.723279  root_mean_squared_error        2.477052       0.431206   75.958508                 0.270844                0.058297           7.424673            2       True         16\n",
      "16   NeuralNetTorch_BAG_L1      -4.967481  -4.725654  root_mean_squared_error        0.244829       0.128131    9.278258                 0.244829                0.128131           9.278258            1       True          8\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t161s\t = DyStack   runtime |\t439s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 439s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_145358\"\n",
      "Train Data Rows:    173\n",
      "Train Data Columns: 329\n",
      "Label Column:       FAQ_future\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16266.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\t0.1s = Fit runtime\n",
      "\t329 features in original data used to generate 329 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 439.11s of the 439.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.40%)\n",
      "\t-3.3299\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 435.71s of the 435.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.42%)\n",
      "\t-3.2813\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 431.94s of the 431.93s of remaining time.\n",
      "\t-3.2876\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 431.03s of the 431.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.11%)\n",
      "\t-3.6577\t = Validation score   (-root_mean_squared_error)\n",
      "\t50.88s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 378.05s of the 378.04s of remaining time.\n",
      "\t-3.2881\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 377.51s of the 377.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.9744\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.48s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 366.87s of the 366.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.85%)\n",
      "\t-3.9794\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 360.05s of the 360.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-4.5621\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.68s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 347.82s of the 347.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.69%)\n",
      "\t-3.4842\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 312.37s of the 312.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.97%)\n",
      "\t-3.6365\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 277.67s of the 277.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-4.0337\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.71s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 265.71s of the 265.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.71%)\n",
      "\t-2.9425\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.96s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 261.29s of the 261.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.9163\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.94s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 247.94s of the 247.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.04%)\n",
      "\t-3.9513\t = Validation score   (-root_mean_squared_error)\n",
      "\t198.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 46.57s of the 46.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.21%)\n",
      "\t-4.2928\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 41.48s of the 41.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-4.1742\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.05s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 29.14s of the 29.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.12%)\n",
      "\t-3.7099\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 4.74s of the 4.73s of remaining time.\n",
      "\t-3.3176\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3.86s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r131_BAG_L1': 0.722, 'NeuralNetTorch_r79_BAG_L1': 0.222, 'RandomForestMSE_BAG_L1': 0.056}\n",
      "\t-2.8224\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 435.43s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 151.9 rows/s (22 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_145358\")\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(['PTID', 'EXAMDATE'])\n",
    "\n",
    "df_sorted['FAQ_future'] = df_sorted.groupby('PTID')['FAQ'].shift(-1)\n",
    "df_sorted['dFAQ'] = df_sorted['FAQ_future'] - df_sorted['FAQ']\n",
    "df_sorted = df_sorted.dropna(subset=['FAQ', 'FAQ_future', 'dFAQ'])\n",
    "\n",
    "df_sorted['time_years'] = (df_sorted.groupby('PTID')['EXAMDATE'].shift(-1) - df_sorted['EXAMDATE']).dt.days / 365.25\n",
    "df_sorted = df_sorted[df_sorted['time_years'] > 0.1]\n",
    "\n",
    "unique_ptids = df_sorted['PTID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ptids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_sorted[df_sorted['PTID'].isin(train_ids)]\n",
    "df_test  = df_sorted[df_sorted['PTID'].isin(test_ids)]\n",
    "\n",
    "\n",
    "cortical_cols = [col for col in df.columns if col.startswith('ST')]\n",
    "extra_cols = ['MMSE', 'AGE', 'APOE4', 'PTEDUCAT', 'CDRSB', 'ADAS13']\n",
    "extra_cols_available = [col for col in extra_cols if col in df.columns]\n",
    "features = cortical_cols + extra_cols_available\n",
    "target = 'FAQ_future'  \n",
    "\n",
    "train_data = df_train[features + [target]].dropna()\n",
    "test_data  = df_test[features + [target]].dropna()\n",
    "\n",
    "predictor4 = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f266c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance metrics:\n",
      "root_mean_squared_error: -2.5827\n",
      "mean_squared_error: -6.6704\n",
      "mean_absolute_error: -1.5696\n",
      "r2: 0.6487\n",
      "pearsonr: 0.8145\n",
      "median_absolute_error: -0.9814\n"
     ]
    }
   ],
   "source": [
    "performance = predictor4.evaluate(test_data)\n",
    "print(\"Test performance metrics:\")\n",
    "for metric, value in performance.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d05d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 329 features using 48 rows with 5 shuffle sets...\n",
      "\t396.17s\t= Expected runtime (79.23s per shuffle set)\n",
      "\t13.56s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features:\n",
      "         importance    stddev   p_value  n  p99_high   p99_low\n",
      "CDRSB      1.460146  0.448872  0.000949  5  2.384380  0.535913\n",
      "MMSE       0.139679  0.120560  0.030320  5  0.387915 -0.108556\n",
      "ST71SV     0.101739  0.114767  0.059250  5  0.338046 -0.134569\n",
      "ADAS13     0.098859  0.076315  0.022134  5  0.255993 -0.058275\n",
      "ST32TA     0.032249  0.042599  0.082875  5  0.119962 -0.055463\n",
      "AGE        0.020171  0.003113  0.000066  5  0.026581  0.013760\n",
      "ST107TS    0.018847  0.007690  0.002699  5  0.034681  0.003013\n",
      "ST130SA    0.011967  0.003483  0.000772  5  0.019139  0.004795\n",
      "ST117CV    0.011430  0.008457  0.019539  5  0.028843 -0.005983\n",
      "ST114SA    0.011231  0.005453  0.004996  5  0.022459  0.000002\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor4.feature_importance(test_data)\n",
    "print(\"Top 10 important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40ccae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.822411</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.204940</td>\n",
       "      <td>12.467399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_r131_BAG_L1</td>\n",
       "      <td>-2.942499</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>1.958362</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>1.958362</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-3.281320</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>1.478223</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>1.478223</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-3.287620</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.796072</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.796072</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-3.288051</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.433512</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.433512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val              eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L2  -2.822411  root_mean_squared_error       0.204940   \n",
       "1    LightGBM_r131_BAG_L1  -2.942499  root_mean_squared_error       0.020016   \n",
       "2         LightGBM_BAG_L1  -3.281320  root_mean_squared_error       0.015330   \n",
       "3  RandomForestMSE_BAG_L1  -3.287620  root_mean_squared_error       0.068865   \n",
       "4    ExtraTreesMSE_BAG_L1  -3.288051  root_mean_squared_error       0.056091   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  12.467399                0.000000           0.005004            2   \n",
       "1   1.958362                0.020016           1.958362            1   \n",
       "2   1.478223                0.015330           1.478223            1   \n",
       "3   0.796072                0.068865           0.796072            1   \n",
       "4   0.433512                0.056091           0.433512            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         19  \n",
       "1       True         12  \n",
       "2       True          2  \n",
       "3       True          3  \n",
       "4       True          5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor4.leaderboard(silent=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabc1b6",
   "metadata": {},
   "source": [
    "В качестве эксперимента целевой переменной берется `dFAQ`, то есть на сколько изменится показатель в следующий визит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05127821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251214_150409\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          20\n",
      "Memory Avail:       17.02 GB / 31.64 GB (53.8%)\n",
      "Disk Space Avail:   377.34 GB / 838.35 GB (45.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\sechenovka\\AutogluonModels\\ag-20251214_150409\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestMSE_BAG_L2      -3.017722  -3.349349  root_mean_squared_error        2.607578       0.434762  64.903518                 0.075985                0.048219           0.975269            2       True         14\n",
      "1   RandomForestMSE_BAG_L1      -3.121170  -3.339776  root_mean_squared_error        0.105244       0.078847   1.121909                 0.105244                0.078847           1.121909            1       True          3\n",
      "2     ExtraTreesMSE_BAG_L2      -3.212781  -3.194367  root_mean_squared_error        2.584977       0.436210  64.368617                 0.053384                0.049668           0.440368            2       True         16\n",
      "3     ExtraTreesMSE_BAG_L1      -3.228677  -3.322413  root_mean_squared_error        0.151486       0.048121   0.419608                 0.151486                0.048121           0.419608            1       True          5\n",
      "4   NeuralNetFastAI_BAG_L1      -3.306153  -2.970914  root_mean_squared_error        0.716254       0.060917   7.289815                 0.716254                0.060917           7.289815            1       True          6\n",
      "5      WeightedEnsemble_L2      -3.345560  -2.946204  root_mean_squared_error        1.550539       0.219742  58.929647                 0.012541                0.001003           0.004997            2       True         11\n",
      "6        LightGBMXT_BAG_L1      -3.386577  -3.024801  root_mean_squared_error        0.410977       0.019834   0.571611                 0.410977                0.019834           0.571611            1       True          1\n",
      "7           XGBoost_BAG_L1      -3.393695  -3.133430  root_mean_squared_error        0.325888       0.021003   2.890471                 0.325888                0.021003           2.890471            1       True          7\n",
      "8          CatBoost_BAG_L1      -3.399755  -3.005227  root_mean_squared_error        0.566376       0.039064  37.808684                 0.566376                0.039064          37.808684            1       True          4\n",
      "9          CatBoost_BAG_L2      -3.406429  -3.074592  root_mean_squared_error        2.661874       0.476607  89.170834                 0.130281                0.090064          25.242584            2       True         15\n",
      "10   NeuralNetTorch_BAG_L1      -3.433131  -3.005561  root_mean_squared_error        0.255368       0.118758  13.826150                 0.255368                0.118758          13.826150            1       True          8\n",
      "11       LightGBMXT_BAG_L2      -3.433940  -3.054857  root_mean_squared_error        2.628217       0.409165  64.643075                 0.096624                0.022622           0.714826            2       True         12\n",
      "12    CatBoost_r177_BAG_L1      -3.435580  -3.029611  root_mean_squared_error        0.136218       0.047003   7.011034                 0.136218                0.047003           7.011034            1       True         10\n",
      "13     WeightedEnsemble_L3      -3.439539  -2.893813  root_mean_squared_error        2.830241       0.454067  71.520233                 0.012098                0.000000           0.005998            3       True         18\n",
      "14  NeuralNetFastAI_BAG_L2      -3.476482  -2.922972  root_mean_squared_error        2.818143       0.454067  71.514235                 0.286550                0.067525           7.585986            2       True         17\n",
      "15         LightGBM_BAG_L1      -3.482950  -3.087027  root_mean_squared_error        0.161047       0.017001   0.562042                 0.161047                0.017001           0.562042            1       True          2\n",
      "16    LightGBMLarge_BAG_L1      -3.487928  -3.110175  root_mean_squared_error        0.096331       0.017001   2.173772                 0.096331                0.017001           2.173772            1       True          9\n",
      "17         LightGBM_BAG_L2      -3.526821  -3.072280  root_mean_squared_error        2.668120       0.412542  68.401145                 0.136527                0.026000           4.472896            2       True         13\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t160s\t = DyStack   runtime |\t440s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 440s\n",
      "AutoGluon will save models to \"d:\\sechenovka\\AutogluonModels\\ag-20251214_150409\"\n",
      "Train Data Rows:    173\n",
      "Train Data Columns: 329\n",
      "Label Column:       dFAQ\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17257.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 328 | ['ST101SV', 'ST102CV', 'ST102SA', 'ST102TA', 'ST102TS', ...]\n",
      "\t\t('int', [])   :   1 | ['PTEDUCAT']\n",
      "\t0.1s = Fit runtime\n",
      "\t329 features in original data used to generate 329 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 440.11s of the 440.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.38%)\n",
      "\t-3.0801\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 433.78s of the 433.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.37%)\n",
      "\t-3.1057\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 430.24s of the 430.24s of remaining time.\n",
      "\t-3.3676\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 428.93s of the 428.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.91%)\n",
      "\t-3.0799\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.27s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 386.48s of the 386.47s of remaining time.\n",
      "\t-3.2679\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 385.97s of the 385.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.1093\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 376.08s of the 376.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.85%)\n",
      "\t-3.1487\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 369.84s of the 369.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-3.0904\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.67s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 358.88s of the 358.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.73%)\n",
      "\t-3.1138\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 353.48s of the 353.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.18%)\n",
      "\t-3.1043\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 313.48s of the 313.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-3.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.42s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 302.04s of the 302.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.65%)\n",
      "\t-3.1053\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 298.23s of the 298.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.1695\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.59s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 286.32s of the 286.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.38%)\n",
      "\t-3.0987\t = Validation score   (-root_mean_squared_error)\n",
      "\t101.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 182.43s of the 182.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.20%)\n",
      "\t-3.0738\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 179.25s of the 179.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-3.0821\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.16s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 168.90s of the 168.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.79%)\n",
      "\t-3.0904\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 152.59s of the 152.58s of remaining time.\n",
      "\t-3.2961\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 151.83s of the 151.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.48%)\n",
      "\t-3.0481\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.77s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 132.99s of the 132.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.2023\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.97s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 122.90s of the 122.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.01%)\n",
      "\t-3.1421\t = Validation score   (-root_mean_squared_error)\n",
      "\t98.74s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 21.75s of the 21.74s of remaining time.\n",
      "\t-3.2864\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 20.66s of the 20.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.46%)\n",
      "\t-3.0546\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.44s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 14.83s of the 14.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t-3.014\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.35s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3.88s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.364, 'NeuralNetFastAI_r145_BAG_L1': 0.364, 'XGBoost_r33_BAG_L1': 0.227, 'CatBoost_r137_BAG_L1': 0.045}\n",
      "\t-2.9592\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 436.41s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 102.5 rows/s (22 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\sechenovka\\AutogluonModels\\ag-20251214_150409\")\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(['PTID', 'EXAMDATE'])\n",
    "\n",
    "df_sorted['FAQ_future'] = df_sorted.groupby('PTID')['FAQ'].shift(-1)\n",
    "df_sorted['dFAQ'] = df_sorted['FAQ_future'] - df_sorted['FAQ']\n",
    "df_sorted = df_sorted.dropna(subset=['FAQ', 'FAQ_future', 'dFAQ'])\n",
    "\n",
    "df_sorted['time_years'] = (df_sorted.groupby('PTID')['EXAMDATE'].shift(-1) - df_sorted['EXAMDATE']).dt.days / 365.25\n",
    "df_sorted = df_sorted[df_sorted['time_years'] > 0.1]\n",
    "\n",
    "unique_ptids = df_sorted['PTID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ptids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_sorted[df_sorted['PTID'].isin(train_ids)]\n",
    "df_test  = df_sorted[df_sorted['PTID'].isin(test_ids)]\n",
    "\n",
    "\n",
    "cortical_cols = [col for col in df.columns if col.startswith('ST')]\n",
    "extra_cols = ['MMSE', 'AGE', 'APOE4', 'PTEDUCAT', 'CDRSB', 'ADAS13']\n",
    "extra_cols_available = [col for col in extra_cols if col in df.columns]\n",
    "features = cortical_cols + extra_cols_available\n",
    "target = 'dFAQ'  \n",
    "\n",
    "train_data = df_train[features + [target]].dropna()\n",
    "test_data  = df_test[features + [target]].dropna()\n",
    "\n",
    "predictor5 = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='best_quality',\n",
    "    time_limit=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ed5dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance metrics:\n",
      "root_mean_squared_error: -1.8174\n",
      "mean_squared_error: -3.3031\n",
      "mean_absolute_error: -1.2550\n",
      "r2: -0.1167\n",
      "pearsonr: 0.0387\n",
      "median_absolute_error: -0.8730\n"
     ]
    }
   ],
   "source": [
    "performance = predictor5.evaluate(test_data)\n",
    "print(\"Test performance metrics:\")\n",
    "for metric, value in performance.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b23fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 329 features using 48 rows with 5 shuffle sets...\n",
      "\t613.17s\t= Expected runtime (122.63s per shuffle set)\n",
      "\t39.11s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features:\n",
      "         importance    stddev   p_value  n  p99_high   p99_low\n",
      "ST18SV     0.015604  0.005256  0.001336  5  0.026425  0.004782\n",
      "ST98TS     0.012903  0.007789  0.010381  5  0.028941 -0.003135\n",
      "ST121SA    0.012032  0.008158  0.014994  5  0.028829 -0.004765\n",
      "ST90TS     0.011696  0.003869  0.001249  5  0.019663  0.003730\n",
      "ST2SV      0.009940  0.004520  0.003973  5  0.019246  0.000633\n",
      "ST118TS    0.009906  0.002360  0.000359  5  0.014765  0.005047\n",
      "ST85SA     0.009515  0.001803  0.000147  5  0.013227  0.005804\n",
      "ST58SA     0.007121  0.002494  0.001545  5  0.012257  0.001986\n",
      "ST105TS    0.006814  0.001861  0.000606  5  0.010646  0.002983\n",
      "ST116TS    0.006578  0.002871  0.003435  5  0.012489  0.000667\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor5.feature_importance(test_data)\n",
    "print(\"Top 10 important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e085b0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.959164</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.214597</td>\n",
       "      <td>48.449170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
       "      <td>-3.013987</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>8.351059</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>8.351059</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_r137_BAG_L1</td>\n",
       "      <td>-3.048112</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>16.773144</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>16.773144</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
       "      <td>-3.054213</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>9.415429</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>9.415429</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_r188_BAG_L1</td>\n",
       "      <td>-3.054645</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>3.443737</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>3.443737</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score_val              eval_metric  \\\n",
       "0          WeightedEnsemble_L2  -2.959164  root_mean_squared_error   \n",
       "1  NeuralNetFastAI_r145_BAG_L1  -3.013987  root_mean_squared_error   \n",
       "2         CatBoost_r137_BAG_L1  -3.048112  root_mean_squared_error   \n",
       "3    NeuralNetTorch_r79_BAG_L1  -3.054213  root_mean_squared_error   \n",
       "4         LightGBM_r188_BAG_L1  -3.054645  root_mean_squared_error   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0       0.214597  48.449170                0.000000           0.013111   \n",
       "1       0.067491   8.351059                0.067491           8.351059   \n",
       "2       0.037021  16.773144                0.037021          16.773144   \n",
       "3       0.080170   9.415429                0.080170           9.415429   \n",
       "4       0.022157   3.443737                0.022157           3.443737   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            2       True         25  \n",
       "1            1       True         24  \n",
       "2            1       True         19  \n",
       "3            1       True         11  \n",
       "4            1       True         23  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor5.leaderboard(silent=True).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
